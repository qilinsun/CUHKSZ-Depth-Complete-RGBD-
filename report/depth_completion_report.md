# Base Pipeline : CostDCNet

![pipeline](pipeline.jpg)

# Dataset: Matterport

    dataset/
    ├── 17DRP5sb8fy
    │   ├── render_depth
    │   │   ├── resize_00ebbf3782c64d74aaf7dd39cd561175_d0_0_mesh_depth.png
    │   │   └── ...
    │   ├── undistorted_color_images
    │   │   ├── resize_00ebbf3782c64d74aaf7dd39cd561175_i0_0.jpg
    │   │   └── ...
    │   └── undistorted_depth_images
    │       ├── resize_00ebbf3782c64d74aaf7dd39cd561175_d0_0.png
    │       └── ...
    └─── 1LXtFkjw3qL
         └── ...

Following matterport3D dataset, the data orginization in this repository is shown above. In experiment, all images are resized to 256x320.
## Undistorted Color Image
undistorted_color_images : resized original rgb images

## Undistorted Depth Image
Reprojected depth images aligned with the color images. Every depth image a 16 bit PNG containing the pixel's distance in the z-direction from the camera center (not the euclidean distance from the camera center), `0.25 mm` per value (divide by 4000 to get meters).

## Render Depth
render_depth : ground truth depth map generated by multiview-reconstruction method (also in yindaZ's work)


## Example

<center class="half">
    <img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_i1_1.jpg" width="300"/>
    <img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_d1_1.png" width="300"/>
    <img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_d1_1_mesh_depth.png" width="300"/>
</center>

# Our Data for evaluation

    dataset/
    ├── cropped_interpo_depth
    │   ├── frame-000000.depth.png
    │   │   └── ...
    └── cropped_rgb
        ├── frame-000000.color.png
        └── ...

In experiment, all images are cropped to 1080 * 864
## Cropped Color Image
Original RGB Image cropped to 1080 * 864. In `PNG` format.

## Cropped interpolated depth
Every depth image a `16` bit `PNG`. Depth scale $1000$, `1mm` per value (divide bt 1000 to get meters). Depth image are aligned to RGB image, and interpolated by linear interpolation.

## Example
<center class="half">
    <img src="dataset_intro/our_data/frame-000001.color.png" width="400"/>
    <img src="dataset_intro/our_data/frame-000001.depth.png" width="400"/>

</center>


# Training using Silog Loss:

## Silog Loss

$$ L = \alpha\sqrt{\frac{1}{K}\sum_i{\Delta d_i^2} - \frac{\lambda}{K^2}(\sum_i{\Delta d_i})^2}$$

where $\Delta d_i = \log{\hat{d_i}} - \log{d_i^*}$. $\hat{d_i}$ is the predicted depth value and $d_i^*$ is the ground truth depth value.

$\lambda$ is a variance minimizing factor, and $\alpha$ is a scale constant. In this experiment, $\lambda$ is set to 0.85 and $\alpha$ is set to 10.

K is the number of valid depth values in GT depth image.

## Training Input and Output From Matterport Dataset

<center class="half">
    <img src="silog_loss/resize_23f90479f2cf4c60bc78cb3252fe64e8_i1_1.jpg" width="300"/>
    <img src="silog_loss/raw_dep_fzynW3qQPVF_23f90479f2cf4c60bc78cb3252fe64e8_d1_1_8.png" width="300"/>
    <img src="silog_loss/pred_dep_fzynW3qQPVF_23f90479f2cf4c60bc78cb3252fe64e8_d1_1_8.png" width="300"/>
</center>

<center class="half">
    <img src="silog_loss/resize_4c90d6eff5534ef5a18642fad9622e28_i1_2.jpg" width="300"/>
    <img src="silog_loss/raw_dep_5ZKStnWn8Zo_4c90d6eff5534ef5a18642fad9622e28_d1_2_5.png" width="300"/>
    <img src="silog_loss/pred_dep_5ZKStnWn8Zo_4c90d6eff5534ef5a18642fad9622e28_d1_2_5.png" width="300"/>
</center>


## Testing Input and Output of Our data