# Base Pipeline : CostDCNet

![pipeline](pipeline.jpg)

# Dataset: Matterport

    dataset/
    ├── 17DRP5sb8fy
    │   ├── render_depth
    │   │   ├── resize_00ebbf3782c64d74aaf7dd39cd561175_d0_0_mesh_depth.png
    │   │   └── ...
    │   ├── undistorted_color_images
    │   │   ├── resize_00ebbf3782c64d74aaf7dd39cd561175_i0_0.jpg
    │   │   └── ...
    │   └── undistorted_depth_images
    │       ├── resize_00ebbf3782c64d74aaf7dd39cd561175_d0_0.png
    │       └── ...
    └─── 1LXtFkjw3qL
         └── ...

Following matterport3D dataset, the data orginization in this repository is shown above. In experiment, all images are resized to 256x320.
## Undistorted Color Image
undistorted_color_images : resized original rgb images

## Undistorted Depth  ( Raw depth image)
Reprojected depth images aligned with the color images. Every depth image a 16 bit PNG containing the pixel's distance in the z-direction from the camera center (not the euclidean distance from the camera center), `0.25 mm` per value (divide by 4000 to get meters).

## Render Depth ( Ground Truth image)
render_depth : ground truth depth map generated by multiview-reconstruction method (also in yindaZ's work)


## Example

<center class="half">
    <img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_i1_1.jpg" width="300"/><img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_d1_1.png" width="300"/><img src="dataset_intro/matterport/resize_23f90479f2cf4c60bc78cb3252fe64e8_d1_1_mesh_depth.png" width="300"/>
</center>

# Our Data for evaluation

    dataset/
    ├── cropped_interpo_depth
    │   ├── frame-000000.depth.png
    │   │   └── ...
    └── cropped_rgb
        ├── frame-000000.color.png
        └── ...

In experiment, all images are cropped to 1080 * 864
## Cropped Color Image
Original RGB Image cropped to 1080 * 864. In `PNG` format.

## Cropped interpolated depth
Every depth image a `16` bit `PNG`. Depth scale $1000$, `1mm` per value (divide bt 1000 to get meters). Depth image are aligned to RGB image, and interpolated by linear interpolation.

## Example
<center class="half">
    <img src="dataset_intro/our_data/frame-000001.color.png" width="400"/><img src="dataset_intro/our_data/frame-000001.depth.png" width="400"/>

</center>


# Training Pipeline
![pipeline](pipeline.jpg)

## Data Preprocessing

1. In training stage, Matterport Ground Truth depth and Raw Depth are dvided by 4000(convert to get meters). In evaluating stage, our data's groud truth depth and raw depth are diveded by 1000 to get meters.
2. RGB image are normalized to 0~1, (divided by 255).

## RGB-D Feature Volume Construction

RGB-D feature volume construction has two branches in order to extracting 2D and 3D feature maps from input RGB-D image.

1. 3D feature map extraction needs a 3D encoder. Thus, the input depth image is converted into a Multiple Depth Plane. In experiment, the number of depth plane are chosen to be `16` and maximum depth are chosen to be `15`. A sparse 3D convolution is applied to the Multiple Depth Plane to compute features only for valid 3D points with depth vaue > 0.

2. To obtain 2D feature map, we need to concatenate depth image and RGB image, then feed into a 2D encoder.

3. RGB-D feature volume are constructed based on the 3D feature map and 2D feature map. 

## Cost Volume Prediction

Based on the RGB-D Volume, a cost volume is obtained by feeding RGB-D feature volume ino a 3D UNet. Then Per plane pixel-shuffle is applied to upsample the cost volume to restore the original resolution.

## Depth Regression

We can regress a completed depth map $D^′(·)$ by applying the softmax operator $\sigma( · )$ to the upsampled cost volume $V_c \in \mathbb{R}^{W ×H×K}$ along the depth-axis and using the following equation
$$D^′(x, y) =\sum^K_{k=1}d_k × p^k_{x,y} $$
$$p_{x,y} = \sigma(V_c(x, y, :))$$
where $d_k$ is the predefined depth value of the k-th plane, (x, y) is an image pixel position, K is the number of depth planes, $V_c(x, y, :)$ is a K-dimensional vector along the depth-axis within the cost volume, and px,y is a probability vector obtained by the softmax operator σ( · ) for K depth planes at (x, y).
# Training using Silog Loss:

## Silog Loss

$$ L = \alpha\sqrt{\frac{1}{K}\sum_i{\Delta d_i^2} - \frac{\lambda}{K^2}(\sum_i{\Delta d_i})^2}$$

where $\Delta d_i = \log{\hat{d_i}} - \log{d_i^*}$. 

$\hat{d_i}$ is the predicted depth value and $d_i^*$ is the ground truth depth value.

$\lambda$ is a variance minimizing factor, and $\alpha$ is a scale constant. In this experiment, $\lambda$ is set to 0.85 and $\alpha$ is set to 10.

K is the number of valid depth values in GT depth image.

## Training Input and Output From Matterport Dataset
### RGB image, Raw Depth image, Predicted Image and GT image.

![](silog_loss/matterport/combine/4c90d6eff5534ef5a18642fad9622e28_i1_2.jpg)
![](silog_loss/matterport/combine/23f90479f2cf4c60bc78cb3252fe64e8_i1_1.jpg)


## Testing Input and Output of Our data
### RGB image, Raw Depth image, Predicted Image

![](silog_loss/ourdata/combine/frame-000000.png)
![](silog_loss/ourdata/combine/frame-000001.png)
![](silog_loss/ourdata/combine/frame-000002.png)
![](silog_loss/ourdata/combine/frame-000003.png)

more result: see [silog_loss result on our data](silog_loss/ourdata/combine/)

# Training Using L1 loss + gradient loss (Training in Progress)

Use Gradient loss proposed by Learning an Efficient Multimodal Depth
Completion Model.

$$L_{cgdl}(\hat{Y}, Y) = ||F(\hat{Y}) - F(Y)||_p * E(sgn(Y\in v))$$

$$L(\hat{Y}, Y) = L_{l1}(\hat{Y}, Y) + \lambda*L_{cgdl}(\hat{Y}, Y)$$

$L_{cgdl}$ is corrected gradient loss. $\hat{Y}$ is the ground truth depth. $Y$ is the predicted depth.

## Training Input and Output
### RGB image, Raw Depth image, Predicted Image and GT image.

![](batchsize_16_gradientloss/matterport/combine/5ZKStnWn8Zo_4c90d6eff5534ef5a18642fad9622e28_d1_2.png)
![](batchsize_16_gradientloss/matterport/combine/fzynW3qQPVF_23f90479f2cf4c60bc78cb3252fe64e8_d1_1.png)
![](batchsize_16_gradientloss/matterport/combine/UwV83HsGsw3_53abab7fbeff4b61842d457eff7406ce_d1_4.png)
![](batchsize_16_gradientloss/matterport/combine/gxdoqLR6rwA_142124e9a2c84be59a8facb7db858a53_d1_0.png)
![](batchsize_16_gradientloss/matterport/combine/fzynW3qQPVF_7f4f8df6c0de4998992a5f1951a1bb64_d1_3.png)

Testing Metrics RMSE 0.8773 | REL 0.6531 | d1: 0.8479 | d2: 0.9085 | d3: 0.9318

## Ourdata
### RGB image, Raw Depth image, Predicted Image

![](batchsize_16_gradientloss/ourdata/combine/frame-000000.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000001.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000002.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000003.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000004.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000005.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000006.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000007.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000008.png)
![](batchsize_16_gradientloss/ourdata/combine/frame-000009.png)

more result: see [gradient_loss result on our data](batchsize_16_gradientloss/ourdata/combine/)

## Evaluation SSIM & PSNR

### Paper (matterport dataset)

| RMSE | MAE | ssim | d1 | d2 | d3 |
| ---  | ---  | ---  | ---  | ---  | ---  |
| `1.019` | `0.290` | `0.838`| `0.871` | `0.928` | `0.948` |

### l1 loss (matterport dataset)

| RMSE | MAE | ssim | psnr | d1 | d2 | d3 | REL |
| ---  | ---  | ---  | ---  | ---  | ---  | ---  | --- |
| `0.8953` | `0.4299` | `0.9259`| `56.4660`| `0.8487` | `0.9068` | `0.9308` | `0.6501` |

### l1 + gradient loss (matterport dataset)


| RMSE | MAE | ssim | psnr | d1 | d2 | d3 | REL |
| ---  | ---  | ---  | ---  | ---  | ---  | ---  | --- |
| `0.8781` | `0.4228` | `0.9234`| `56.7954`| `0.8513` | `0.9092` | `0.9325` | `0.6403` |

### l1 loss (our data)

compare the predicted depth with raw depth

without valid mask:

| RMSE| MAE | ssim | psnr | mse |
| ---  | ---  | --- | ---  | --- |
| `2.5719`| `1.8116` | `0.5870`| `28.6766`| `7.2165` |

with valid mask:

| mask_RMSE | mask_MAE | mask_ssim | mask_psnr | mask_mse |
| ---  | ---  | --- | ---  | ---  |
| `0.1506` |`0.0252` |`0.9997`|`57.3338`| `0.0544` |

# After Resize the our image 

paper 中使用的数据集直接将高分辨率的图像resize成320*256的图像。

将我们的图像resize成320*256之后喂入网络，结果如下

![](data0929/combine/frame-000000.png)
![](data0929/combine/frame-000001.png)
![](data0929/combine/frame-000002.png)
![](data0929/combine/frame-000003.png)
![](data0929/combine/frame-000004.png)
![](data0929/combine/frame-000005.png)
![](data0929/combine/frame-000006.png)
![](data0929/combine/frame-000007.png)
![](data0929/combine/frame-000008.png)
![](data0929/combine/frame-000009.png)

more result: see [resized result on our data](batchsize_16_gradientloss/ourdata/combine/)

compare the predicted depth with raw depth



| unresize RMSE| unresize MAE| unresize ssim | unresize psnr | unresize mse |
| ---  | ---  | --- | ---  | --- |
| `2.5719`| `1.8116`|`0.5870`| `28.6766`| `7.2165` |
| resize RMSE | resize MAE | resize ssim | resize psnr | resize mse |
| `2.6816` | `2.0797` |`0.5152`| `28.3615`| `7.8534` |

with valid mask

| unresize mask_RMSE | unresize mask_MAE | unresize mask_ssim | unresize mask_psnr | unresize mask_mse |
| ---  | ---  | --- | ---  | ---  |
| `0.1506` | `0.0252` |`0.9997`|`57.3338`| `0.0544` |
| resize mask_RMSE | resize mask_MAE | resize mask_ssim | resize mask_psnr | resize mask_mse |
| `0.6317` | `0.1863` |`0.9916`| `40.6668`| `0.4256` |

with valid mask, compare predicted depth and raw depth on `matterport dataset`

| mask_RMSE | mask_MAE | mask_ssim | mask_psnr | mask_mse |
| ---  | ---  | --- | ---  | ---  |
| `0.7188` | `0.2412` |`0.9331`|`31.0013`| `0.8913` |

# Compare resize and original size

## 从左到右依次为，RGB, 输入深度图, resize过后预测深度图，resize之前预测深度图
![](data0929_1219_compare/frame-000000.png)
![](data0929_1219_compare/frame-000001.png)
![](data0929_1219_compare/frame-000002.png)
![](data0929_1219_compare/frame-000003.png)
![](data0929_1219_compare/frame-000004.png)
![](data0929_1219_compare/frame-000005.png)
![](data0929_1219_compare/frame-000006.png)
![](data0929_1219_compare/frame-000007.png)
![](data0929_1219_compare/frame-000008.png)
![](data0929_1219_compare/frame-000009.png)

<!-- # New Captured data
![](data1219/dorm/combine/d10_p0_RGB_t202824163.png)
![](data1219/dorm/combine/d11_p0_RGB_t220357278.png)
![](data1219/dorm/combine/d12_p0_RGB_t234957097.png)
![](data1219/dorm/combine/d14_p0_RGB_t272706634.png)
![](data1219/dorm/combine/d2_p0_RGB_t61792621.png)
![](data1219/dorm/combine/d15_p0_RGB_t291473071.png)

| ssim | psnr |
| ---  | ---  |
|`0.524553`| `7.980019`|

with valid mask:

| ssim | psnr |
| ---  | ---  |
|`0.847129`|`16.355815`| -->
